{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing **Dependencies**"
      ],
      "metadata": {
        "id": "AabikXim_bzf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "TmB4bg9kThI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for data handling, preprocessing, modeling, and evaluation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "9xP7L6jpTf3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load and Explore Data**"
      ],
      "metadata": {
        "id": "0BhbsZg6TsVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset and perform initial exploration\n",
        "def load_data(file_path):\n",
        "    data = pd.read_csv('/content/tested.csv')\n",
        "    print(\"First 5 rows of the dataset:\\n\", data.head())\n",
        "    print(\"\\nDataset information:\\n\", data.info())\n",
        "    print(\"\\nMissing values:\\n\", data.isnull().sum())\n",
        "    return data\n",
        "\n",
        "# Usage\n",
        "data = load_data(\"/content/tested.csv\")  # Replace with your file path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNQJ2jvNTf84",
        "outputId": "d68b277c-881d-4f39-8727-cf6bd21d56d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the dataset:\n",
            "    PassengerId  Survived  Pclass  \\\n",
            "0          892         0       3   \n",
            "1          893         1       3   \n",
            "2          894         0       2   \n",
            "3          895         0       3   \n",
            "4          896         1       3   \n",
            "\n",
            "                                           Name     Sex   Age  SibSp  Parch  \\\n",
            "0                              Kelly, Mr. James    male  34.5      0      0   \n",
            "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
            "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
            "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
            "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
            "\n",
            "    Ticket     Fare Cabin Embarked  \n",
            "0   330911   7.8292   NaN        Q  \n",
            "1   363272   7.0000   NaN        S  \n",
            "2   240276   9.6875   NaN        Q  \n",
            "3   315154   8.6625   NaN        S  \n",
            "4  3101298  12.2875   NaN        S  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 418 entries, 0 to 417\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  418 non-null    int64  \n",
            " 1   Survived     418 non-null    int64  \n",
            " 2   Pclass       418 non-null    int64  \n",
            " 3   Name         418 non-null    object \n",
            " 4   Sex          418 non-null    object \n",
            " 5   Age          332 non-null    float64\n",
            " 6   SibSp        418 non-null    int64  \n",
            " 7   Parch        418 non-null    int64  \n",
            " 8   Ticket       418 non-null    object \n",
            " 9   Fare         417 non-null    float64\n",
            " 10  Cabin        91 non-null     object \n",
            " 11  Embarked     418 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 39.3+ KB\n",
            "\n",
            "Dataset information:\n",
            " None\n",
            "\n",
            "Missing values:\n",
            " PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age             86\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             1\n",
            "Cabin          327\n",
            "Embarked         0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "JM_oLmAvUIpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values, encode categorical variables, and normalize numerical data\n",
        "def preprocess_data(df):\n",
        "    # Handle missing values\n",
        "    df['Age'].fillna(df['Age'].median(), inplace=True)  # Fill missing age with median\n",
        "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)  # Fill missing embarked with mode\n",
        "    df['Cabin'] = df['Cabin'].apply(lambda x: 1 if pd.notna(x) else 0)  # Cabin known: 1, unknown: 0\n",
        "\n",
        "    # Drop irrelevant columns\n",
        "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
        "\n",
        "    # Encode categorical variables\n",
        "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})  # Male: 0, Female: 1\n",
        "    df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)  # One-hot encoding for Embarked\n",
        "\n",
        "    # Normalize numerical features\n",
        "    scaler = StandardScaler()\n",
        "    df[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\n",
        "\n",
        "    # Fix infinite values\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    df.fillna(df.max(), inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "# Apply preprocessing\n",
        "processed_data = preprocess_data(data)\n",
        "print(\"Preprocessed data:\\n\", processed_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YNTUwWwTgEY",
        "outputId": "fc32f3a2-5c90-47f9-fbdd-dfae29917dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed data:\n",
            "    Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Cabin  Embarked_Q  \\\n",
            "0         0       3    0  0.386231      0      0 -0.497811      0        True   \n",
            "1         1       3    1  1.371370      1      0 -0.512660      0       False   \n",
            "2         0       2    0  2.553537      0      0 -0.464532      0        True   \n",
            "3         0       3    0 -0.204852      0      0 -0.482888      0       False   \n",
            "4         1       3    1 -0.598908      1      1 -0.417971      0       False   \n",
            "\n",
            "   Embarked_S  \n",
            "0       False  \n",
            "1        True  \n",
            "2       False  \n",
            "3        True  \n",
            "4        True  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-b6a58b796cbf>:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Age'].fillna(df['Age'].median(), inplace=True)  # Fill missing age with median\n",
            "<ipython-input-51-b6a58b796cbf>:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)  # Fill missing embarked with mode\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "RMQfdiaJUT7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create new features to improve model performance\n",
        "def engineer_features(df):\n",
        "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1  # Family size = siblings + parents + 1\n",
        "    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)  # Alone: 1, Not alone: 0\n",
        "    return df\n",
        "\n",
        "# Apply feature engineering\n",
        "final_data = engineer_features(processed_data)\n",
        "print(\"Data with engineered features:\\n\", final_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBGbFGreTgJi",
        "outputId": "9b9b2221-0c3a-490c-a153-b3f59efe5751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with engineered features:\n",
            "    Survived  Pclass  Sex       Age  SibSp  Parch      Fare  Cabin  Embarked_Q  \\\n",
            "0         0       3    0  0.386231      0      0 -0.497811      0        True   \n",
            "1         1       3    1  1.371370      1      0 -0.512660      0       False   \n",
            "2         0       2    0  2.553537      0      0 -0.464532      0        True   \n",
            "3         0       3    0 -0.204852      0      0 -0.482888      0       False   \n",
            "4         1       3    1 -0.598908      1      1 -0.417971      0       False   \n",
            "\n",
            "   Embarked_S  FamilySize  IsAlone  \n",
            "0       False           1        1  \n",
            "1        True           2        0  \n",
            "2       False           1        1  \n",
            "3        True           1        1  \n",
            "4        True           3        0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train - Test split**"
      ],
      "metadata": {
        "id": "Kdd75Wx4UbPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "def split_data(df, target='Survived', test_size=0.2, random_state=42):\n",
        "    X = df.drop(target, axis=1)  # Features\n",
        "    y = df[target]  # Target (Survived)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "    print(f\"Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Apply split\n",
        "X_train, X_test, y_train, y_test = split_data(final_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nduME3x0TgTg",
        "outputId": "ce21cd4d-0dd1-44be-acf2-4229c9fcf861"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 334, Test size: 84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training and Evaluation**"
      ],
      "metadata": {
        "id": "QnGLojPQUkie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train multiple models and evaluate their performance\n",
        "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        model.fit(X_train, y_train)  # Train the model\n",
        "        y_pred = model.predict(X_test)  # Predict on test data\n",
        "\n",
        "        results[name] = {\n",
        "            'Accuracy': accuracy_score(y_test, y_pred),\n",
        "            'Precision': precision_score(y_test, y_pred),\n",
        "            'Recall': recall_score(y_test, y_pred),\n",
        "            'F1-Score': f1_score(y_test, y_pred)\n",
        "        }\n",
        "\n",
        "    # Print results\n",
        "    for name, metrics in results.items():\n",
        "        print(f\"\\n{name}:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "    return models\n",
        "\n",
        "# Train models\n",
        "trained_models = train_and_evaluate(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8X-XLW7Ujml",
        "outputId": "083a859a-1558-476d-d0fc-aa4891d19752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Logistic Regression:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "\n",
            "XGBoost:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [05:14:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "RewP9iMOUyOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune the Random Forest model with the best parameters\n",
        "def tune_model(X_train, y_train, model=RandomForestClassifier(random_state=42)):\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200],  # Number of trees\n",
        "        'max_depth': [10, 20, None],  # Tree depth\n",
        "        'min_samples_split': [2, 5]   # Minimum samples for split\n",
        "    }\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n",
        "    print(\"Best CV score:\", grid_search.best_score_)\n",
        "\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Tune Random Forest\n",
        "best_model = tune_model(X_train, y_train)\n",
        "y_pred = best_model.predict(X_test)\n",
        "print(\"Final test accuracy:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUa-eBQkUj1Q",
        "outputId": "6d8ad841-fc88-4511-8df2-9b246b6eff2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Best CV score: 1.0\n",
            "Final test accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}